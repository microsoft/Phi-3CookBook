# **Cuantizaci贸n de Phi-3.5 usando Intel OpenVINO**

Intel es el fabricante de CPU m谩s tradicional con muchos usuarios. Con el auge del aprendizaje autom谩tico y el aprendizaje profundo, Intel tambi茅n se ha unido a la competencia por la aceleraci贸n de IA. Para la inferencia de modelos, Intel no solo utiliza GPUs y CPUs, sino tambi茅n NPUs.

Esperamos desplegar la Familia Phi-3.x en el lado final, con la esperanza de convertirse en la parte m谩s importante de la PC de IA y la PC Copilot. La carga del modelo en el lado final depende de la cooperaci贸n de diferentes fabricantes de hardware. Este cap铆tulo se centra principalmente en el escenario de aplicaci贸n de Intel OpenVINO como un modelo cuantitativo.

## **驴Qu茅 es OpenVINO?**

OpenVINO es un kit de herramientas de c贸digo abierto para optimizar y desplegar modelos de aprendizaje profundo desde la nube hasta el borde. Acelera la inferencia de aprendizaje profundo en varios casos de uso, como IA generativa, video, audio y lenguaje, con modelos de marcos populares como PyTorch, TensorFlow, ONNX y m谩s. Convierte y optimiza modelos, y despliega en una mezcla de hardware y entornos Intel庐, en las instalaciones y en el dispositivo, en el navegador o en la nube.

Ahora con OpenVINO, puedes cuantizar r谩pidamente el modelo GenAI en hardware de Intel y acelerar la referencia del modelo.

Ahora OpenVINO admite la conversi贸n de cuantizaci贸n de Phi-3.5-Vision y Phi-3.5 Instruct.

### **Configuraci贸n del Entorno**

Por favor, aseg煤rate de que las siguientes dependencias del entorno est茅n instaladas, esto es requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Cuantizaci贸n de Phi-3.5-Instruct usando OpenVINO**

En Terminal, por favor ejecuta este script

```bash

export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}

```

### **Cuantizaci贸n de Phi-3.5-Vision usando OpenVINO**

Por favor, ejecuta este script en Python o Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)

model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### ** Ejemplos para Phi-3.5 con Intel OpenVINO**

| Labs    | Introducci贸n | Ir |
| -------- | ------- |  ------- |
|  Lab-Introduce Phi-3.5 Instruct  | Aprende c贸mo usar Phi-3.5 Instruct en tu PC de IA    |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
|  Lab-Introduce Phi-3.5 Vision (imagen) | Aprende c贸mo usar Phi-3.5 Vision para analizar im谩genes en tu PC de IA      |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
|  Lab-Introduce Phi-3.5 Vision (video)   | Aprende c贸mo usar Phi-3.5 Vision para analizar im谩genes en tu PC de IA    |  [Ir](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Recursos**

1. Aprende m谩s sobre Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Repositorio GitHub de Intel OpenVINO [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

Aviso legal: La traducci贸n fue realizada a partir del original por un modelo de IA y puede no ser perfecta. 
Por favor, revise el resultado y haga las correcciones necesarias.