**Ajuste fino de Phi-3 con QLoRA**

Ajuste fino del modelo de lenguaje Phi-3 Mini de Microsoft utilizando [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora). 

QLoRA ayudará a mejorar la comprensión conversacional y la generación de respuestas. 

Para cargar modelos en 4 bits con transformers y bitsandbytes, debes instalar accelerate y transformers desde la fuente y asegurarte de tener la última versión de la biblioteca bitsandbytes.

**Ejemplos**
- [Aprende más con este notebook de ejemplo](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Ejemplo de ajuste fino en Python](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Ejemplo de ajuste fino en Hugging Face Hub con LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Ejemplo de ajuste fino en Hugging Face Hub con QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducción automática basados en inteligencia artificial. Si bien nos esforzamos por garantizar la precisión, tenga en cuenta que las traducciones automatizadas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que puedan surgir del uso de esta traducción.