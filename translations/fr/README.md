# Phi-3 Cookbook : Exemples pratiques avec les mod√®les Phi-3 de Microsoft

[![Open and use the samples in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)
[![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/phi-3cookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phi-3cookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/phi-3cookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phi-3cookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/phi-3cookbook?style=social&label=Star)](https://GitHub.com/microsoft/phi-3cookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Azure AI Community Discord](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi est une famille de mod√®les d'IA ouverts d√©velopp√©s par Microsoft. Les mod√®les Phi sont les plus performants et les plus rentables parmi les petits mod√®les de langage (SLM) disponibles, surpassant les mod√®les de m√™me taille et ceux de taille sup√©rieure dans divers benchmarks de langage, de raisonnement, de codage et de math√©matiques. La famille Phi-3 comprend des versions mini, petite, moyenne et vision, entra√Æn√©es sur diff√©rentes quantit√©s de param√®tres pour r√©pondre √† divers sc√©narios d'application. Pour plus d'informations d√©taill√©es sur la famille Phi de Microsoft, veuillez visiter la page [Bienvenue dans la famille Phi](/md/01.Introduce/Phi3Family.md).

Suivez ces √©tapes :
1. **Forker le d√©p√¥t** : Cliquez sur le bouton "Fork" en haut √† droite de cette page.
2. **Cloner le d√©p√¥t** : `git clone https://github.com/microsoft/Phi-3CookBook.git`

![Phi3Family](/imgs/00/Phi3getstarted.png)

## Table des mati√®res

- Introduction
  - [Configurer votre environnement](./md/01.Introduce/EnvironmentSetup.md)(‚úÖ)
  - [Bienvenue dans la famille Phi](./md/01.Introduce/Phi3Family.md)(‚úÖ)
  - [Comprendre les technologies cl√©s](./md/01.Introduce/Understandingtech.md)(‚úÖ)
  - [S√©curit√© de l'IA pour les mod√®les Phi](./md/01.Introduce/AISafety.md)(‚úÖ)
  - [Support mat√©riel pour Phi-3](./md/01.Introduce/Hardwaresupport.md)(‚úÖ)
  - [Mod√®les Phi-3 et disponibilit√© sur les plateformes](./md/01.Introduce/Edgeandcloud.md)(‚úÖ)
  - [Utiliser Guidance-ai et Phi](./md/01.Introduce/Guidance.md)(‚úÖ)
  - [Mod√®les du GitHub Marketplace](https://github.com/marketplace/models)(‚úÖ)
  - [Catalogue de mod√®les Azure AI](https://ai.azure.com)(‚úÖ)

- D√©marrage rapide
  - [Utiliser Phi-3 dans le catalogue de mod√®les GitHub](./md/02.QuickStart/GitHubModel_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans Hugging Face](./md/02.QuickStart/Huggingface_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 avec le SDK OpenAI](./md/02.QuickStart/OpenAISDK_Quickstart.md)(‚úÖ)
  - [Utiliser Phi-3 avec des requ√™tes HTTP](./md/02.QuickStart/HttpAPI_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans Azure AI Studio](./md/02.QuickStart/AzureAIStudio_QuickStart.md)(‚úÖ)
  - [Utiliser l'inf√©rence de mod√®le Phi-3 avec Azure MaaS ou MaaP](./md/02.QuickStart/AzureModel_Inference.md)(‚úÖ)
  - [Utiliser l'API d'inf√©rence Azure avec GitHub et Azure AI](./md/02.QuickStart/AzureInferenceAPI_QuickStart.md)
  - [D√©ployer des mod√®les Phi-3 en tant qu'APIs serverless dans Azure AI Studio](./md/02.QuickStart/AzureAIStudio_MaaS.md)(‚úÖ)
  - [Utiliser Phi-3 dans Ollama](./md/02.QuickStart/Ollama_QuickStart.md)(‚úÖ)
- [Utiliser Phi-3 dans LM Studio](./md/02.QuickStart/LMStudio_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans AI Toolkit VSCode](./md/02.QuickStart/AITookit_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 et LiteLLM](./md/02.QuickStart/LiteLLM_QuickStart.md)(‚úÖ)
  
- [Inf√©rence Phi-3](./md/03.Inference/overview.md)  
  - [Inf√©rence Phi-3 sur iOS](./md/03.Inference/iOS_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3.5 sur Android](./md/08.Update/Phi35/050.UsingPhi35TFLiteCreateAndroidApp.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur Jetson](./md/03.Inference/Jetson_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur PC AI](./md/03.Inference/AIPC_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec Apple MLX Framework](./md/03.Inference/MLX_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur Serveur Local](./md/03.Inference/Local_Server_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur Serveur Distant avec AI Toolkit](./md/03.Inference/Remote_Interence.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec Rust](./md/03.Inference/Rust_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3-Vision en Local](./md/03.Inference/Vision_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/03.Inference/Kaito_Inference.md)(‚úÖ)
  - [Inf√©rence de Votre Mod√®le Fine-tuning avec ONNX Runtime](./md/06.E2ESamples/E2E_Inference_ORT.md)(‚úÖ)

- Fine-tuning Phi-3
  - [T√©l√©chargement & Cr√©ation d'un Jeu de Donn√©es Exemple](./md/04.Fine-tuning/CreatingSampleData.md)(‚úÖ)
  - [Sc√©narios de Fine-tuning](./md/04.Fine-tuning/FineTuning_Scenarios.md)(‚úÖ)
  - [Fine-tuning vs RAG](./md/04.Fine-tuning/FineTuning_vs_RAG.md)(‚úÖ)
  - [Fine-tuning : Faire de Phi-3 un expert industriel](./md/04.Fine-tuning/LetPhi3gotoIndustriy.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec AI Toolkit pour VS Code](./md/04.Fine-tuning/Finetuning_VSCodeaitoolkit.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec Azure Machine Learning Service](./md/04.Fine-tuning/Introduce_AzureML.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec Lora](./md/04.Fine-tuning/FineTuning_Lora.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec QLora](./md/04.Fine-tuning/FineTuning_Qlora.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec Azure AI Studio](./md/04.Fine-tuning/FineTuning_AIStudio.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec Azure ML CLI/SDK](./md/04.Fine-tuning/FineTuning_MLSDK.md)(‚úÖ)
  - [Fine-tuning avec Microsoft Olive](./md/04.Fine-tuning/FineTuning_MicrosoftOlive.md)(‚úÖ)
  - [Fine-tuning avec Microsoft Olive Hands-On Lab](./code/04.Finetuning/olive-lab/readme.md)(‚úÖ)
  - [Fine-tuning Phi-3-vision avec Weights and Bias](./md/04.Fine-tuning/FineTuning_Phi-3-visionWandB.md)(‚úÖ)
  - [Fine-tuning Phi-3 avec Apple MLX Framework](./md/04.Fine-tuning/FineTuning_MLX.md)(‚úÖ)
  - [Fine-tuning Phi-3-vision (support officiel)](./md/04.Fine-tuning/FineTuning_Vision.md)(‚úÖ)
- [Fine-Tuning Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/04.Fine-tuning/FineTuning_Kaito.md)(‚úÖ)
  - [Fine-Tuning Phi-3 et 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)(‚úÖ)

- √âvaluation Phi-3
  - [Introduction √† l'IA Responsable](./md/05.Evaluation/ResponsibleAI.md)(‚úÖ)
  - [Introduction √† Promptflow](./md/05.Evaluation/Promptflow.md)(‚úÖ)
  - [Introduction √† Azure AI Studio pour l'√©valuation](./md/05.Evaluation/AzureAIStudio.md)(‚úÖ)

- Exemples E2E pour Phi-3-mini
  - [Introduction aux exemples de bout en bout](./md/06.E2ESamples/E2E_Introduction.md)(‚úÖ)
  - [Pr√©parez vos donn√©es industrielles](./md/06.E2ESamples/E2E_Datasets.md)(‚úÖ)
  - [Utilisez Microsoft Olive pour architecturer vos projets](./md/06.E2ESamples/E2E_LoRA&QLoRA_Config_With_Olive.md)(‚úÖ)
  - [Chatbot local sur Android avec Phi-3, ONNXRuntime Mobile et ONNXRuntime Generate API](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/mobile/examples/phi-3/android)(‚úÖ)
  - [D√©monstration Hugging Face Space WebGPU et Phi-3-mini - Phi-3-mini offre √† l'utilisateur une exp√©rience de chatbot priv√©e (et puissante). Vous pouvez l'essayer](https://huggingface.co/spaces/Xenova/experimental-phi3-webgpu)(‚úÖ)
  - [Chatbot local dans le navigateur utilisant Phi3, ONNX Runtime Web et WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)(‚úÖ)
  - [Chat OpenVino](/md/06.E2ESamples/E2E_OpenVino_Chat.md)(‚úÖ)
  - [Multi Mod√®le - Phi-3-mini interactif et OpenAI Whisper](./md/06.E2ESamples/E2E_Phi-3-mini_with_whisper.md)(‚úÖ)
  - [MLFlow - Construire un wrapper et utiliser Phi-3 avec MLFlow](./md/06.E2ESamples/E2E_Phi-3-MLflow.md)(‚úÖ)
  - [Optimisation de mod√®le - Comment optimiser le mod√®le Phi-3-min pour ONNX Runtime Web avec Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)(‚úÖ)
  - [Application WinUI3 avec Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)(‚úÖ)
  - [Exemple d'application de notes aliment√©e par l'IA WinUI3 Multi Mod√®le](https://github.com/microsoft/ai-powered-notes-winui3-sample)(‚úÖ)
  - [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow](./md/06.E2ESamples/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)(‚úÖ)
  - [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow dans Azure AI Studio](./md/06.E2ESamples/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIstudio.md)(‚úÖ)
  - [√âvaluer le mod√®le Phi-3 / Phi-3.5 affin√© dans Azure AI Studio en se concentrant sur les principes de l'IA Responsable de Microsoft](./md/06.E2ESamples/E2E_Phi-3-Evaluation_AIstudio.md)(‚úÖ)
  - [Exemple de pr√©diction linguistique Phi-3.5-mini-instruct (Chinois/Anglais)](../../code/09.UpdateSamples/Aug/phi3-instruct-demo.ipynb)(‚úÖ)

- Exemples E2E pour Phi-3-vision
  - [Phi-3-vision-Image texte en texte](../../code/06.E2E/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)(‚úÖ)
  - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)(‚úÖ)
  - [Phi-3-vision CLIP Embedding](./md/06.E2ESamples/E2E_Phi-3-Embedding_Images_with_CLIPVision.md)(‚úÖ)
  - [DEMO : Phi-3 Recycling](https://github.com/jennifermarsman/PhiRecycling/)(‚úÖ)
  - [Phi-3-vision - Assistant visuel linguistique avec Phi3-Vision et OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)(‚úÖ)
  - [Phi-3 Vision Nvidia NIM](/md/06.E2ESamples/E2E_Nvidia_NIM_Vision.md)(‚úÖ)
  - [Phi-3 Vision OpenVino](/md/06.E2ESamples/E2E_OpenVino_Phi3Vision.md)(‚úÖ)
  - [Exemple multi-image ou multi-frame Phi-3.5 Vision](../../code/09.UpdateSamples/Aug/phi3-vision-demo.ipynb)(‚úÖ)

- Exemples E2E pour Phi-3.5-MoE
  - [Exemple de mod√®les Mixture of Experts (MoEs) Phi-3.5 pour les r√©seaux sociaux](../../code/09.UpdateSamples/Aug/phi3_moe_demo.ipynb)(‚úÖ)
- [Construire un pipeline de g√©n√©ration augment√©e par r√©cup√©ration (RAG) avec NVIDIA NIM Phi-3 MOE, Azure AI Search et LlamaIndex](https://github.com/farzad528/azure-ai-search-python-playground/blob/main/azure-ai-search-nvidia-rag.ipynb)(‚úÖ)

- Exemples de laboratoires et d'ateliers Phi-3
  - [Laboratoires C# .NET](./md/07.Labs/Csharp/csharplabs.md)(‚úÖ)
  - [Construisez votre propre Visual Studio Code GitHub Copilot Chat avec Microsoft Phi-3 Family](./md/07.Labs/VSCode/README.md)(‚úÖ)
  - [Exemples de chatbot Mini RAG WebGPU Phi-3 avec fichier RAG local](./code/08.RAG/rag_webgpu_chat/README.md)(‚úÖ)
  - [Tutoriel Phi-3 ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html)(‚úÖ)
  - [Tutoriel Phi-3-vision ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)(‚úÖ)
  - [Ex√©cuter les mod√®les Phi-3 avec l'API generate() d'ONNX Runtime](https://github.com/microsoft/onnxruntime-genai/blob/main/examples/python/phi-3-tutorial.md)(‚úÖ)
  - [Interface de chat Multi Mod√®le LLM Phi-3 ONNX, Ceci est une d√©mo de chat](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/chat_app)(‚úÖ)
  - [Exemple C# Hello Phi-3 ONNX Phi-3](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/csharp/HelloPhi)(‚úÖ)
  - [Exemple d'API C# Phi-3 ONNX pour supporter Phi3-Vision](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/csharp/HelloPhi3V)(‚úÖ)
  - [Ex√©cuter des exemples C# Phi-3 dans un CodeSpace](./md/07.Labs/CsharpOllamaCodeSpaces/CsharpOllamaCodeSpaces.md)(‚úÖ)
  - [Utiliser Phi-3 avec Promptflow et Azure AI Search](./code/07.Lab/RAG_with_PromptFlow_and_AISearch/README.md)(‚úÖ)
  - [API Windows AI-PC avec la biblioth√®que Windows Copilot](https://developer.microsoft.com/windows/ai/?WT.mc_id=aiml-137032-kinfeylo)

- Apprentissage de Phi-3.5
  - [Quoi de neuf dans la famille Phi-3.5](./md/08.Update/Phi35/010.WhatsNewInPhi35.md)(‚úÖ)
  - [Quantification de la famille Phi-3.5](./md/08.Update/Phi35/020.QuantifyingPhi35.md)(‚úÖ)
    - [Quantification de Phi-3.5 avec llama.cpp](./md/08.Update/Phi35/021.UsingLlamacppQuantifyingPhi35.md)(‚úÖ)
    - [Quantification de Phi-3.5 avec les extensions d'IA g√©n√©rative pour onnxruntime](./md/08.Update/Phi35/022.UsingORTGenAIQuantifyingPhi35.md)(‚úÖ)
    - [Quantification de Phi-3.5 avec Intel OpenVINO](./md/08.Update/Phi35/023.UsingIntelOpenVINOQuantifyingPhi35.md)(‚úÖ)
    - [Quantification de Phi-3.5 avec le framework Apple MLX](./md/08.Update/Phi35/024.UsingAppleMLXQuantifyingPhi35.md)(‚úÖ)
  - Exemples d'applications Phi-3.5
    - [Chatbot RAG WebGPU Phi-3.5-Instruct](./md/08.Update/Phi35/031.WebGPUWithPhi35Readme.md)(‚úÖ)
    - [Cr√©ez votre propre agent de chat Copilot Visual Studio Code avec Phi-3.5 via les mod√®les GitHub](./md/08.Update/Phi35/032.CreateVSCodeChatAgentWithGitHubModels.md)(‚úÖ)
    - [Utiliser le GPU Windows pour cr√©er une solution de flux d'invite avec Phi-3.5-Instruct ONNX](./md/08.Update/Phi35/040.UsingPromptFlowWithONNX.md)(‚úÖ)
    - [Utiliser Microsoft Phi-3.5 tflite pour cr√©er une application Android](./md/08.Update/Phi35/050.UsingPhi35TFLiteCreateAndroidApp.md)(‚úÖ)


## Utiliser les mod√®les Phi-3

### Phi-3 sur Azure AI Studio

Vous pouvez apprendre √† utiliser Microsoft Phi-3 et √† cr√©er des solutions E2E sur vos diff√©rents appareils mat√©riels. Pour exp√©rimenter Phi-3 par vous-m√™me, commencez par jouer avec le mod√®le et personnaliser Phi-3 pour vos sc√©narios en utilisant le‚ÄØ[Azure AI Foundry Azure AI Model Catalog](https://aka.ms/phi3-azure-ai). Vous pouvez en savoir plus en d√©marrant avec [Azure AI Studio](/md/02.QuickStart/AzureAIStudio_QuickStart.md)

**Playground**
Chaque mod√®le a un terrain de jeu d√©di√© pour tester le mod√®le [Azure AI Playground](https://aka.ms/try-phi3).

### Phi-3 sur les mod√®les GitHub

Vous pouvez apprendre √† utiliser Microsoft Phi-3 et √† cr√©er des solutions E2E sur vos diff√©rents appareils mat√©riels. Pour exp√©rimenter Phi-3 par vous-m√™me, commencez par jouer avec le mod√®le et personnaliser Phi-3 pour vos sc√©narios en utilisant le‚ÄØ[GitHub Model Catalog](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo). Vous pouvez en savoir plus en d√©marrant avec [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md)

**Playground**
Chaque mod√®le a un [terrain de jeu d√©di√© pour tester le mod√®le](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi-3 sur Hugging Face

Vous pouvez √©galement trouver le mod√®le sur [Hugging Face](https://huggingface.co/microsoft)

**Playground**
[Hugging Chat playground](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## üåê Support Multilingue

> **Note:**
> Ces traductions ont √©t√© g√©n√©r√©es automatiquement √† l'aide de l'outil open-source [co-op-translator](https://github.com/Azure/co-op-translator) et peuvent contenir des erreurs ou des inexactitudes. Pour des informations cruciales, il est recommand√© de se r√©f√©rer √† l'original ou de consulter une traduction humaine professionnelle. Si vous souhaitez ajouter ou mettre √† jour une traduction, veuillez vous r√©f√©rer au d√©p√¥t [co-op-translator](https://github.com/Azure/co-op-translator), o√π vous pouvez facilement contribuer en utilisant des commandes simples.

| Langue               | Code | Lien vers le README traduit                             | Derni√®re mise √† jour |
|----------------------|------|---------------------------------------------------------|----------------------|
| Chinois (Simplifi√©)  | zh   | [Traduction en chinois](../zh/README.md)    | 2024-10-04           |
| Chinois (Traditionnel)| tw  | [Traduction en chinois](../tw/README.md)    | 2024-10-04           |
| Fran√ßais             | fr   | [Traduction en fran√ßais](./README.md)   | 2024-10-04           |
| Japonais             | ja   | [Traduction en japonais](../ja/README.md)   | 2024-10-04           |
| Cor√©en               | ko   | [Traduction en cor√©en](../ko/README.md)     | 2024-10-04           |
| Espagnol             | es   | [Traduction en espagnol](../es/README.md)   | 2024-10-04           |

## Marques de commerce

Ce projet peut contenir des marques de commerce ou des logos pour des projets, produits ou services. L'utilisation autoris√©e des marques de commerce ou des logos de Microsoft est soumise aux [Directives d'utilisation des marques et de la marque Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
L'utilisation des marques de commerce ou des logos de Microsoft dans des versions modifi√©es de ce projet ne doit pas cr√©er de confusion ou impliquer un parrainage de Microsoft. Toute utilisation de marques de commerce ou de logos de tiers est soumise aux politiques de ces tiers.

**Avertissement**:
Ce document a √©t√© traduit en utilisant des services de traduction automatique bas√©s sur l'IA. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.