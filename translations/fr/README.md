# Phi-3 Cookbook : Exemples pratiques avec les mod√®les Phi-3 de Microsoft

[![Ouvrir et utiliser les exemples dans GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)
[![Ouvrir dans Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)
[![Pull-requests GitHub](https://img.shields.io/github/issues-pr/microsoft/phi-3cookbook.svg)](https://GitHub.com/microsoft/phi-3cookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)
[![PRs Bienvenus](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/phi-3cookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phi-3cookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/phi-3cookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phi-3cookbook/network/?WT.mc_id=aiml-137032-kinfeylo)
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/phi-3cookbook?style=social&label=Star)](https://GitHub.com/microsoft/phi-3cookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Azure AI Community Discord](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi est une famille de mod√®les d'IA ouverts d√©velopp√©s par Microsoft. Les mod√®les Phi sont les mod√®les de langage de petite taille les plus performants et les plus rentables disponibles, surpassant les mod√®les de m√™me taille et de taille sup√©rieure dans divers benchmarks de langage, de raisonnement, de codage et de math√©matiques. La famille Phi-3 comprend des versions mini, petite, moyenne et vision, entra√Æn√©es avec diff√©rentes quantit√©s de param√®tres pour r√©pondre √† divers sc√©narios d'application. Pour plus d'informations d√©taill√©es sur la famille Phi de Microsoft, veuillez visiter la page [Bienvenue dans la famille Phi](/md/01.Introduce/Phi3Family.md).

![Phi3Family](/imgs/00/Phi3getstarted.png)

## Table des mati√®res

- Introduction
  - [Configurer votre environnement](./md/01.Introduce/EnvironmentSetup.md)(‚úÖ)
  - [Bienvenue dans la famille Phi](./md/01.Introduce/Phi3Family.md)(‚úÖ)
  - [Comprendre les technologies cl√©s](./md/01.Introduce/Understandingtech.md)(‚úÖ)
  - [S√©curit√© de l'IA pour les mod√®les Phi](./md/01.Introduce/AISafety.md)(‚úÖ)
  - [Support mat√©riel pour Phi-3](./md/01.Introduce/Hardwaresupport.md)(‚úÖ)
  - [Mod√®les Phi-3 & Disponibilit√© sur diff√©rentes plateformes](./md/01.Introduce/Edgeandcloud.md)(‚úÖ)
  - [Utilisation de Guidance-ai et Phi](./md/01.Introduce/Guidance.md)(‚úÖ)

- D√©marrage rapide
  - [Utiliser Phi-3 dans le catalogue de mod√®les GitHub](./md/02.QuickStart/GitHubModel_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans Hugging face](./md/02.QuickStart/Huggingface_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 avec OpenAI SDK](./md/02.QuickStart/OpenAISDK_Quickstart.md)(‚úÖ)
  - [Utiliser Phi-3 avec des requ√™tes Http](./md/02.QuickStart/HttpAPI_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans Azure AI Studio](./md/02.QuickStart/AzureAIStudio_QuickStart.md)(‚úÖ)
  - [Utiliser l'inf√©rence de mod√®le Phi-3 avec Azure MaaS ou MaaP](./md/02.QuickStart/AzureModel_Inference.md)(‚úÖ)
  - [D√©ployer des mod√®les Phi-3 en tant qu'APIs serverless dans Azure AI Studio](./md/02.QuickStart/AzureAIStudio_MaaS.md)(‚úÖ)
  - [Utiliser Phi-3 dans Ollama](./md/02.QuickStart/Ollama_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans LM Studio](./md/02.QuickStart/LMStudio_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 dans AI Toolkit VSCode](./md/02.QuickStart/AITookit_QuickStart.md)(‚úÖ)
  - [Utiliser Phi-3 et LiteLLM](./md/02.QuickStart/LiteLLM_QuickStart.md)(‚úÖ)
- [Inf√©rence Phi-3](./md/03.Inference/overview.md)  
  - [Inf√©rence Phi-3 sur iOS](./md/03.Inference/iOS_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur Jetson](./md/03.Inference/Jetson_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur AI PC](./md/03.Inference/AIPC_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec le Framework Apple MLX](./md/03.Inference/MLX_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur un serveur local](./md/03.Inference/Local_Server_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 sur un serveur distant avec AI Toolkit](./md/03.Inference/Remote_Interence.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec Rust](./md/03.Inference/Rust_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3-Vision en local](./md/03.Inference/Vision_Inference.md)(‚úÖ)
  - [Inf√©rence Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/03.Inference/Kaito_Inference.md)(‚úÖ)
  - [Inf√©rence de votre mod√®le ONNX Runtime ajust√©](./md/06.E2ESamples/E2E_Inference_ORT.md)(‚úÖ)

- Ajustement fin de Phi-3
  - [T√©l√©chargement & Cr√©ation d'un jeu de donn√©es d'exemple](./md/04.Fine-tuning/CreatingSampleData.md)(‚úÖ)
  - [Sc√©narios d'ajustement fin](./md/04.Fine-tuning/FineTuning_Scenarios.md)(‚úÖ)
  - [Ajustement fin vs RAG](./md/04.Fine-tuning/FineTuning_vs_RAG.md)(‚úÖ)
  - [Ajustement fin pour que Phi-3 devienne un expert industriel](./md/04.Fine-tuning/LetPhi3gotoIndustriy.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec AI Toolkit pour VS Code](./md/04.Fine-tuning/Finetuning_VSCodeaitoolkit.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec Azure Machine Learning Service](./md/04.Fine-tuning/Introduce_AzureML.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec Lora](./md/04.Fine-tuning/FineTuning_Lora.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec QLora](./md/04.Fine-tuning/FineTuning_Qlora.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec Azure AI Studio](./md/04.Fine-tuning/FineTuning_AIStudio.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec Azure ML CLI/SDK](./md/04.Fine-tuning/FineTuning_MLSDK.md)(‚úÖ)
  - [Ajustement fin avec Microsoft Olive](./md/04.Fine-tuning/FineTuning_MicrosoftOlive.md)(‚úÖ)
  - [Ajustement fin de Phi-3-vision avec Weights and Bias](./md/04.Fine-tuning/FineTuning_Phi-3-visionWandB.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec le Framework Apple MLX](./md/04.Fine-tuning/FineTuning_MLX.md)(‚úÖ)
  - [Ajustement fin de Phi-3-vision (support officiel)](./md/04.Fine-tuning/FineTuning_Vision.md)(‚úÖ)
  - [Ajustement fin de Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/04.Fine-tuning/FineTuning_Kaito.md)(‚úÖ)

- √âvaluation Phi-3
  - [Introduction √† l'IA responsable](./md/05.Evaluation/ResponsibleAI.md)(‚úÖ)
  - [Introduction √† Promptflow](./md/05.Evaluation/Promptflow.md)(‚úÖ)
  - [Introduction √† Azure AI Studio pour l'√©valuation](./md/05.Evaluation/AzureAIStudio.md)(‚úÖ)

- Exemples E2E pour Phi-3-mini
  - [Introduction aux exemples de bout en bout](./md/06.E2ESamples/E2E_Introduction.md)(‚úÖ)
- [Pr√©parez vos donn√©es industrielles](./md/06.E2ESamples/E2E_Datasets.md)(‚úÖ)
  - [Utilisez Microsoft Olive pour architecturer vos projets](./md/06.E2ESamples/E2E_LoRA&QLoRA_Config_With_Olive.md)(‚úÖ)
  - [Chatbot local sur Android avec Phi-3, ONNXRuntime Mobile et ONNXRuntime Generate API](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/mobile/examples/phi-3/android)(‚úÖ)
  - [D√©mo Hugging Face Space WebGPU et Phi-3-mini - Phi-3-mini offre une exp√©rience de chatbot priv√©e (et puissante). Vous pouvez l'essayer](https://huggingface.co/spaces/Xenova/experimental-phi3-webgpu)(‚úÖ)
  - [Chatbot local dans le navigateur utilisant Phi3, ONNX Runtime Web et WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)(‚úÖ)
  - [Chat OpenVino](/md/06.E2ESamples/E2E_OpenVino_Chat.md)(‚úÖ)
  - [Multi Mod√®le - Phi-3-mini interactif et OpenAI Whisper](./md/06.E2ESamples/E2E_Phi-3-mini_with_whisper.md)(‚úÖ)
  - [MLFlow - Construire un wrapper et utiliser Phi-3 avec MLFlow](./md/06.E2ESamples/E2E_Phi-3-MLflow.md)(‚úÖ)
  - [Optimisation de mod√®le - Comment optimiser le mod√®le Phi-3-min pour ONNX Runtime Web avec Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)(‚úÖ)
  - [Application WinUI3 avec Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)(‚úÖ)
  - [Exemple d'application de notes AI multi-mod√®le sous WinUI3](https://github.com/microsoft/ai-powered-notes-winui3-sample)(‚úÖ)
  - [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow](./md/06.E2ESamples/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)(‚úÖ)
  - [Affiner et int√©grer des mod√®les Phi-3 personnalis√©s avec Prompt flow dans Azure AI Studio](./md/06.E2ESamples/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIstudio.md)(‚úÖ)
  - [Exemple de pr√©diction linguistique Phi-3.5-mini-instruct (Chinois/Anglais)](../../code/09.UpdateSamples/Aug/phi3-instruct-demo.ipynb)(‚úÖ)

- Exemples de bout en bout pour Phi-3-vision
  - [Phi-3-vision - Image texte √† texte](../../code/06.E2E/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)(‚úÖ)
  - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)(‚úÖ)
  - [Phi-3-vision CLIP Embedding](./md/06.E2ESamples/E2E_Phi-3-Embedding_Images_with_CLIPVision.md)(‚úÖ)
  - [DEMO : Phi-3 Recyclage](https://github.com/jennifermarsman/PhiRecycling/)(‚úÖ)
  - [Phi-3-vision - Assistant visuel linguistique avec Phi3-Vision et OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)(‚úÖ)
  - [Phi-3 Vision Nvidia NIM](/md/06.E2ESamples/E2E_Nvidia_NIM_Vision.md)(‚úÖ)
  - [Phi-3 Vision OpenVino](/md/06.E2ESamples/E2E_OpenVino_Phi3Vision.md)(‚úÖ)
  - [Exemple multi-image ou multi-cadre Phi-3.5 Vision](../../code/09.UpdateSamples/Aug/phi3-vision-demo.ipynb)(‚úÖ)

- Exemples de bout en bout pour Phi-3.5-MoE
  - [Exemple de r√©seaux sociaux avec mod√®les Mixture of Experts (MoEs) Phi-3.5](../../code/09.UpdateSamples/Aug/phi3_moe_demo.ipynb)(‚úÖ)
  - [Construire un pipeline de g√©n√©ration augment√©e par la r√©cup√©ration (RAG) avec NVIDIA NIM Phi-3 MOE, Azure AI Search et LlamaIndex](https://github.com/farzad528/azure-ai-search-python-playground/blob/main/azure-ai-search-nvidia-rag.ipynb)(‚úÖ)

- Exemples de laboratoires et ateliers Phi-3
  - [Labs C# .NET](./md/07.Labs/Csharp/csharplabs.md)(‚úÖ)
  - [Cr√©ez votre propre chat GitHub Copilot dans Visual Studio Code avec Microsoft Phi-3 Family](./md/07.Labs/VSCode/README.md)(‚úÖ)
  - [Exemples de chatbot local WebGPU Phi-3 Mini RAG avec fichier RAG local](./code/08.RAG/rag_webgpu_chat/README.md)(‚úÖ)
  - [Tutoriel Phi-3 ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html)(‚úÖ)
  - [Tutoriel Phi-3-vision ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)(‚úÖ)
  - [Ex√©cuter les mod√®les Phi-3 avec l'API generate() de ONNX Runtime](https://github.com/microsoft/onnxruntime-genai/blob/main/examples/python/phi-3-tutorial.md)(‚úÖ)
- [Phi-3 ONNX Multi Model LLM Chat UI, Ceci est une d√©mo de chat](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/chat_app)(‚úÖ)
  - [Exemple C# Hello Phi-3 ONNX Phi-3](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/csharp/HelloPhi)(‚úÖ)
  - [Exemple API C# Phi-3 ONNX pour supporter Phi3-Vision](https://github.com/microsoft/onnxruntime-genai/tree/main/examples/csharp/HelloPhi3V)(‚úÖ)
  - [Ex√©cuter des exemples C# Phi-3 dans un CodeSpace](./md/07.Labs/CsharpOllamaCodeSpaces/CsharpOllamaCodeSpaces.md)(‚úÖ)
  - [Utiliser Phi-3 avec Promptflow et Azure AI Search](./code/07.Lab/RAG_with_PromptFlow_and_AISearch/README.md)(‚úÖ)
  - [APIs Windows AI-PC avec la biblioth√®que Windows Copilot](https://developer.microsoft.com/windows/ai/?WT.mc_id=aiml-137032-kinfeylo)

- Apprendre Phi-3.5
  - [Nouveaut√©s de la famille Phi-3.5](./md/08.Update/Phi35/010.WhatsNewInPhi35.md)(‚úÖ)
  - [Quantification de la famille Phi-3.5](./md/08.Update/Phi35/020.QuantifyingPhi35.md)(‚úÖ)
    - [Quantifier Phi-3.5 en utilisant llama.cpp](./md/08.Update/Phi35/021.UsingLlamacppQuantifyingPhi35.md)(‚úÖ)
    - [Quantifier Phi-3.5 en utilisant les extensions d'IA g√©n√©rative pour onnxruntime](./md/08.Update/Phi35/022.UsingORTGenAIQuantifyingPhi35.md)(‚úÖ)
    - [Quantifier Phi-3.5 en utilisant Intel OpenVINO](./md/08.Update/Phi35/023.UsingIntelOpenVINOQuantifyingPhi35.md)(‚úÖ)
    - [Quantifier Phi-3.5 en utilisant le framework Apple MLX](./md/08.Update/Phi35/024.UsingAppleMLXQuantifyingPhi35.md)(‚úÖ)
  - Exemples d'applications Phi-3.5
    - [Phi-3.5-Instruct WebGPU RAG Chatbot](./md/08.Update/Phi35/031.WebGPUWithPhi35Readme.md)(‚úÖ)
    - [Cr√©er votre propre agent Chat Copilot dans Visual Studio Code avec Phi-3.5 par GitHub Models](./md/08.Update/Phi35/032.CreateVSCodeChatAgentWithGitHubModels.md)(‚úÖ)


## Utiliser les mod√®les Phi-3

### Phi-3 sur Azure AI Studio

Vous pouvez apprendre √† utiliser Microsoft Phi-3 et comment construire des solutions E2E sur vos diff√©rents appareils. Pour exp√©rimenter Phi-3 par vous-m√™me, commencez par jouer avec le mod√®le et personnalisez Phi-3 pour vos sc√©narios en utilisant le [Azure AI Studio, Azure AI Model Catalog](https://aka.ms/phi3-azure-ai). Vous pouvez en savoir plus en commen√ßant avec [Azure AI Studio](/md/02.QuickStart/AzureAIStudio_QuickStart.md)

**Playground**
Chaque mod√®le dispose d'un espace de test d√©di√© [Azure AI Playground](https://aka.ms/try-phi3).

### Phi-3 sur GitHub Models

Vous pouvez apprendre √† utiliser Microsoft Phi-3 et comment construire des solutions E2E sur vos diff√©rents appareils. Pour exp√©rimenter Phi-3 par vous-m√™me, commencez par jouer avec le mod√®le et personnalisez Phi-3 pour vos sc√©narios en utilisant le [GitHub Model Catalog](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo). Vous pouvez en savoir plus en commen√ßant avec [GitHub Model Catalog](/md/02.QuickStart/GitHubModel_QuickStart.md)

**Playground**
Chaque mod√®le dispose d'un [espace de test d√©di√©](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi-3 sur Hugging Face

Vous pouvez √©galement trouver le mod√®le sur [Hugging Face](https://huggingface.co/microsoft)

**Playground**
 [Hugging Chat playground](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## üåê Support multilingue

> **Note:**
> Ces traductions ont √©t√© g√©n√©r√©es automatiquement en utilisant le traducteur open-source [co-op-translator](https://github.com/Azure/co-op-translator) et peuvent contenir des erreurs ou des inexactitudes. Pour des informations critiques, il est recommand√© de se r√©f√©rer √† l'original ou de consulter une traduction professionnelle. Si vous souhaitez ajouter ou mettre √† jour une traduction, veuillez consulter le d√©p√¥t [co-op-translator](https://github.com/Azure/co-op-translator), o√π vous pouvez facilement contribuer en utilisant des commandes simples.

| Langue               | Code | Lien vers le README traduit                            | Derni√®re mise √† jour |
|----------------------|------|--------------------------------------------------------|----------------------|
| Chinois (Simplifi√©)  | zh   | [Traduction chinoise](../zh/README.md)     | 2024-09-21           |
| Chinois (Traditionnel)| tw  | [Traduction en chinois](../tw/README.md)   | 2024-09-21           |
| Fran√ßais             | fr   | [Traduction fran√ßaise](./README.md)    | 2024-09-21               |
| Japonais             | ja   | [Traduction japonaise](../ja/README.md)    | 2024-09-21           |
| Cor√©en               | ko   | [Traduction cor√©enne](../ko/README.md)     | 2024-09-21           |
| Espagnol             | es   | [Traduction espagnole](../es/README.md)    | 2024-09-21           |
 
## Marques

Ce projet peut contenir des marques ou des logos pour des projets, produits ou services. L'utilisation autoris√©e des marques ou logos de Microsoft est soumise et doit suivre les [Directives de marque et de logo de Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
L'utilisation des marques ou logos de Microsoft dans des versions modifi√©es de ce projet ne doit pas pr√™ter √† confusion ou impliquer un parrainage de Microsoft. Toute utilisation de marques ou logos de tiers est soumise aux politiques de ces tiers.

