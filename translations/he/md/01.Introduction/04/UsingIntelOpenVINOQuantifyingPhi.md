# **转 Phi-3.5 爪注转 Intel OpenVINO**

  转 爪专转 注 转拽转 转专 注 砖转砖 专. 注 注转 转  砖转  注拽,   爪专驻 转专转 转 爪 砖  转转. 爪专 住拽转 住拽转 ,  砖转砖转  专拽 -GPU -CPU,   -NPU.

 拽 驻专住 转 砖驻转 Phi-3.x 爪 拽爪, 转 砖驻 驻 拽 砖 转专 砖 AI 砖 CoPilot. 注转  爪 拽爪 转 砖转祝 驻注 砖 爪专 专 砖. 驻专拽  转拽 注拽专 转专砖 砖 砖 Intel OpenVINO  转.

## **  OpenVINO**

OpenVINO  注专转  拽 驻转 驻爪 驻专住 砖  砖  注拽,  注 注 拽爪.  抓 住拽转 住拽转 砖  注拽  转专砖,  AI 专, ,  砖驻, 注  住专转 驻驻专转  PyTorch, TensorFlow, ONNX 注. 转 专 爪注 驻爪 , 驻专住 转 注 砖 砖 专转 住转 砖 庐, 驻 拽  注, 驻驻  砖专.

注转, 注 OpenVINO, 转 专转 转 转  -GenAI 注 专转  抓 转 爪注 .

 OpenVINO 转 专转 转 砖 Phi-3.5-Vision -Phi-3.5-Instruct.

### **专转 住**

砖  砖转拽 转转 转 住.  拽抓 requirement.txt:

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **转 Phi-3.5-Instruct 爪注转 OpenVINO**

专, 砖 专抓 转 住拽专驻 :

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **转 Phi-3.5-Vision 爪注转 OpenVINO**

砖 专抓 转 住拽专驻  -Python  -Jupyter Lab:

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### ** 转 -Phi-3.5 注 Intel OpenVINO**

| 注转    | 转专 | 注专 |
| -------- | ------- |  ------- |
|  注 - 专转 注 Phi-3.5 Instruct  |  爪 砖转砖 -Phi-3.5 Instruct 砖 -AI 砖    |  [注专](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
|  注 - 专转 注 Phi-3.5 Vision (转) |  爪 砖转砖 -Phi-3.5 Vision 转 转转 砖 -AI 砖      |  [注专](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
|  注 - 专转 注 Phi-3.5 Vision ()   |  爪 砖转砖 -Phi-3.5 Vision 转 转转 砖 -AI 砖    |  [注专](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **砖**

1. 注 住祝 注 Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. 专 GitHub 砖 Intel OpenVINO [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**转 转专**:  
住  转专 爪注转 砖专转 转专 住住  转转. 注 砖 砖驻 拽, 砖 拽转 砖 砖转专  注砖  砖转  -拽. 住 拽专 砖驻转 拽专转 爪专 砖 拽专 住转. 注 拽专, 抓 砖转砖 转专 砖 拽爪注.   砖 专转 -转  驻专砖转 砖转 注转 砖砖 转专 .