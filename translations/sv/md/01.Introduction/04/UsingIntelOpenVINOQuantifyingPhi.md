# **Kvantifiera Phi-3.5 med Intel OpenVINO**

Intel 칛r den mest traditionella CPU-tillverkaren med m친nga anv칛ndare. Med framv칛xten av maskininl칛rning och djupinl칛rning har Intel ocks친 g친tt med i konkurrensen om AI-acceleration. F칬r modellinferens anv칛nder Intel inte bara GPU:er och CPU:er, utan 칛ven NPU:er.

Vi hoppas kunna distribuera Phi-3.x-familjen p친 klientsidan och bli en viktig del av AI-PC och Copilot-PC. Modellens laddning p친 klientsidan beror p친 samarbetet mellan olika h친rdvarutillverkare. Detta kapitel fokuserar fr칛mst p친 anv칛ndningsscenariot f칬r Intel OpenVINO som en kvantitativ modell.

## **Vad 칛r OpenVINO**

OpenVINO 칛r ett 칬ppen k칛llkod-verktyg f칬r att optimera och distribuera djupinl칛rningsmodeller fr친n moln till edge. Det accelererar djupinl칛rningsinferens 칬ver olika anv칛ndningsomr친den, s친som generativ AI, video, ljud och spr친k med modeller fr친n popul칛ra ramverk som PyTorch, TensorFlow, ONNX och fler. Konvertera och optimera modeller, och distribuera dem 칬ver en mix av Intel춽-h친rdvara och milj칬er, lokalt och p친 enheter, i webbl칛saren eller i molnet.

Med OpenVINO kan du nu snabbt kvantifiera GenAI-modellen p친 Intel-h친rdvara och accelerera modellreferens.

Nu st칬der OpenVINO kvantifieringskonvertering av Phi-3.5-Vision och Phi-3.5 Instruct.

### **Milj칬inst칛llning**

S칛kerst칛ll att f칬ljande milj칬beroenden 칛r installerade, detta 칛r requirement.txt 

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kvantifiera Phi-3.5-Instruct med OpenVINO**

I terminalen, k칬r f칬ljande script:

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kvantifiera Phi-3.5-Vision med OpenVINO**

K칬r detta script i Python eller Jupyter Lab:

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **游뱄 Exempel f칬r Phi-3.5 med Intel OpenVINO**

| Labbar    | Introduktion | G친 till |
| -------- | ------- |  ------- |
| 游 Lab-Introducera Phi-3.5 Instruct  | L칛r dig hur du anv칛nder Phi-3.5 Instruct i din AI-PC    |  [G친 till](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| 游 Lab-Introducera Phi-3.5 Vision (bild) | L칛r dig hur du anv칛nder Phi-3.5 Vision f칬r att analysera bilder i din AI-PC      |  [G친 till](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| 游 Lab-Introducera Phi-3.5 Vision (video)   | L칛r dig hur du anv칛nder Phi-3.5 Vision f칬r att analysera video i din AI-PC    |  [G친 till](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Resurser**

1. L칛s mer om Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av maskinbaserade AI-칬vers칛ttningstj칛nster. 츿ven om vi str칛var efter noggrannhet, v칛nligen notera att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess originalspr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.