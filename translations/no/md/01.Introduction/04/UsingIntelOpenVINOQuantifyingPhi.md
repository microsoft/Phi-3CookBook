# **Kvantisering av Phi-3.5 med Intel OpenVINO**

Intel er den mest tradisjonelle CPU-produsenten med mange brukere. Med fremveksten av maskinl칝ring og dyp l칝ring har Intel ogs친 sluttet seg til konkurransen om AI-akselerasjon. For modellinferens bruker Intel ikke bare GPUer og CPUer, men ogs친 NPUer.

Vi h친per 친 kunne distribuere Phi-3.x-familien p친 sluttbrukerenhetene, og h친per at dette blir den viktigste delen av AI-PC og Copilot-PC. Lastingen av modellen p친 sluttbrukerenhetene avhenger av samarbeidet mellom ulike maskinvareprodusenter. Dette kapittelet fokuserer hovedsakelig p친 bruksomr친det for Intel OpenVINO som en kvantitativ modell.

## **Hva er OpenVINO**

OpenVINO er et 친pen kildekode-verkt칮ysett for 친 optimalisere og distribuere dyp l칝ringsmodeller fra skyen til kantenheter. Det akselererer dyp l칝ringsinfernens p친 tvers av ulike bruksomr친der, som generativ AI, video, lyd og spr친k, med modeller fra popul칝re rammeverk som PyTorch, TensorFlow, ONNX og flere. Konverter og optimaliser modeller, og distribuer dem p친 en blanding av Intel춽-maskinvare og milj칮er, enten lokalt, p친 enheten, i nettleseren eller i skyen.

Med OpenVINO kan du raskt kvantisere GenAI-modellen p친 Intel-maskinvare og akselerere modellreferansen.

OpenVINO st칮tter n친 kvantiseringskonvertering av Phi-3.5-Vision og Phi-3.5 Instruct.

### **Oppsett av milj칮**

S칮rg for at f칮lgende milj칮avhengigheter er installert, dette er requirement.txt 

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Kvantisering av Phi-3.5-Instruct med OpenVINO**

I terminalen, kj칮r dette skriptet:

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Kvantisering av Phi-3.5-Vision med OpenVINO**

Kj칮r dette skriptet i Python eller Jupyter Lab:

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **游뱄 Eksempler for Phi-3.5 med Intel OpenVINO**

| Labs    | Introduksjon | G친 til |
| -------- | ------- |  ------- |
| 游 Lab-Introduksjon til Phi-3.5 Instruct  | L칝r hvordan du bruker Phi-3.5 Instruct p친 din AI-PC    |  [G친 til](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| 游 Lab-Introduksjon til Phi-3.5 Vision (bilde) | L칝r hvordan du bruker Phi-3.5 Vision til 친 analysere bilder p친 din AI-PC      |  [G친 til](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| 游 Lab-Introduksjon til Phi-3.5 Vision (video)   | L칝r hvordan du bruker Phi-3.5 Vision til 친 analysere videoer p친 din AI-PC    |  [G친 til](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Ressurser**

1. L칝r mer om Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub-repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av maskinbaserte AI-oversettelsestjenester. Selv om vi bestreber oss p친 n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiserte oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 dets opprinnelige spr친k b칮r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.